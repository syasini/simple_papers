{
  "1706.03762v7": {
    "title": "Attention Is All You Need",
    "path": "papers/1706.03762v7/1706.03762v7.pdf"
  },
  "2210.03629": {
    "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "path": "papers/2210.03629/2210.03629.pdf"
  },
  "1603.02754v3": {
    "title": "XGBoost: A Scalable Tree Boosting System",
    "path": "papers/1603.02754v3/1603.02754v3.pdf"
  },
  "jair03-lda": {
    "title": "Latent Dirichlet Allocation",
    "path": "papers/jair03-lda/jair03-lda.pdf"
  },
  "2201.11903v6": {
    "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
    "path": "papers/2201.11903v6/2201.11903v6.pdf"
  },
  "2112.10752v2": {
    "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
    "path": "papers/2112.10752v2/2112.10752v2.pdf"
  },
  "1705.07874v2": {
    "title": "A Unified Approach to Interpreting Model Predictions",
    "path": "papers/1705.07874v2/1705.07874v2.pdf"
  },
  "1810.04805v2": {
    "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "path": "papers/1810.04805v2/1810.04805v2.pdf"
  }
}